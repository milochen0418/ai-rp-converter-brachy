{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to seperate program into clear verion and useful functions\n",
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import math\n",
    "from decimal import Decimal\n",
    "import random\n",
    "\n",
    "\n",
    "# The purpose of python_object_dump() is to output python object in bytes, so that\n",
    "# Jupyter notebook can read and show it .\n",
    "import pickle\n",
    "def python_object_dump(obj, filename):\n",
    "    file_w = open(filename, \"wb\")\n",
    "    pickle.dump(obj, file_w)\n",
    "    file_w.close()\n",
    "def python_object_load(filename):\n",
    "    try:\n",
    "        file_r = open(filename, \"rb\")\n",
    "        obj2 = pickle.load(file_r)\n",
    "        file_r.close()\n",
    "    except:\n",
    "        try:\n",
    "            file_r.close()\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "    return obj2\n",
    "\n",
    "\n",
    "def gen_ct_dicom_dict(ct_filelist):\n",
    "    CtCache = {}\n",
    "    CtCache[\"SOPInstanceUID\"] = {}  # Query ct data by the key SOPInstanceUID\n",
    "    CtCache[\"SliceLocation\"] = {}  # Query ct data by the key SliceLocation\n",
    "    CtCache[\"filepath\"] = {}  # Query ct data by the key filepath\n",
    "\n",
    "    for filepath in ct_filelist:\n",
    "        ct_fp = pydicom.read_file(filepath)\n",
    "        ct_SOPInstanceUID = ct_fp.SOPInstanceUID\n",
    "        ct_SliceLocation = ct_fp.SliceLocation\n",
    "        ct_filepath = filepath\n",
    "\n",
    "        ct_dict = {}\n",
    "        ct_dict[\"SOPInstanceUID\"] = ct_SOPInstanceUID\n",
    "        ct_dict[\"SliceLocation\"] = ct_SliceLocation\n",
    "        ct_dict[\"filepath\"] = ct_filepath\n",
    "        # Additional appending data but not key for query\n",
    "        ct_dict[\"ImagePositionPatient_x\"] = ct_fp.ImagePositionPatient[0]  # CT_origin_x\n",
    "        ct_dict[\"ImagePositionPatient_y\"] = ct_fp.ImagePositionPatient[1]  # CT_origin_y\n",
    "        ct_dict[\"ImagePositionPatient_z\"] = ct_fp.ImagePositionPatient[2]  # CT_origin_z, Same as SliceLocation\n",
    "        ct_dict[\"PixelSpacing_x\"] = ct_fp.PixelSpacing[0]  # CT_ps_x\n",
    "        ct_dict[\"PixelSpacing_y\"] = ct_fp.PixelSpacing[1]  # CT_ps_y\n",
    "        ct_dict[\"TableHeight\"] = ct_fp.TableHeight  # Table_H\n",
    "        ct_dict[\"Columns\"] = ct_fp.Columns  # CT_columns\n",
    "        ct_dict[\"Rows\"] = ct_fp.Rows  # CT_rows\n",
    "        ct_dict[\"ROIName\"] = {}\n",
    "        ct_dict[\"pixel_array\"] = copy.deepcopy(ct_fp.pixel_array)\n",
    "        ct_dict[\"RescaleSlope\"] = ct_fp.RescaleSlope\n",
    "        ct_dict[\"RescaleIntercept\"] = ct_fp.RescaleIntercept\n",
    "        ct_dict[\"rescale_pixel_array\"] = ct_fp.pixel_array * ct_fp.RescaleSlope + ct_fp.RescaleIntercept\n",
    "\n",
    "        # Wish can get contourdata[x,y,z...] by ct_dict[\"ROIName\"][roiName][\"ContourData\"]\n",
    "        CtCache[\"SOPInstanceUID\"][ct_SOPInstanceUID] = ct_dict\n",
    "        CtCache[\"SliceLocation\"][ct_SliceLocation] = ct_dict\n",
    "        CtCache[\"filepath\"][ct_filepath] = ct_dict\n",
    "    return CtCache\n",
    "    pass\n",
    "def get_ct_filelist_by_folder(folder):\n",
    "    ct_filelist = []\n",
    "    for file in os.listdir(folder):\n",
    "        # print(file)\n",
    "        filepath = \"{}\\\\{}\".format(folder, file)\n",
    "        file_exists = os.path.isfile(filepath)\n",
    "        if not file_exists:\n",
    "            continue\n",
    "        ct_fp = None\n",
    "        try:\n",
    "            ct_fp = pydicom.read_file(filepath)\n",
    "        except:\n",
    "            # Not dicom file\n",
    "            continue\n",
    "        if ct_fp.Modality != 'CT':\n",
    "            continue\n",
    "        # print(filepath)\n",
    "        ct_filelist.append(filepath)\n",
    "\n",
    "    return ct_filelist\n",
    "\n",
    "def convert_to_gray_image(pixel_array):\n",
    "    img = np.copy(pixel_array)\n",
    "    # Convert to float to avoid overflow or underflow losses.\n",
    "    img_2d = img.astype(float)\n",
    "    # Rescaling grey scale between 0-255\n",
    "    img_2d_scaled = (np.maximum(img_2d, 0) / img_2d.max()) * 255.0\n",
    "    # Convert to uint\n",
    "    img_2d_scaled = np.uint8(img_2d_scaled)\n",
    "    return img_2d_scaled\n",
    "def get_max_contours_by_filter_img(A, filter_img, ContourRetrievalMode=cv2.RETR_EXTERNAL):\n",
    "    # gray_image = cv2.cvtColor(filter_img, cv2.COLOR_RGB2GRAY)\n",
    "    gray_image = filter_img\n",
    "    # findContours\n",
    "    # _, contours, _ = cv2.findContours(gray_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    # _, contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    _, contours, _ = cv2.findContours(gray_image, ContourRetrievalMode, cv2.CHAIN_APPROX_NONE)\n",
    "    return contours\n",
    "def get_max_contours(A, constant_value=None, ContourRetrievalMode=cv2.RETR_EXTERNAL):\n",
    "    constant = None\n",
    "    if constant_value == None:\n",
    "        # Algoruthm to find constant value\n",
    "        data = A.ravel()\n",
    "        sorted_data = np.copy(data)\n",
    "        sorted_data.sort()\n",
    "        constant = sorted_data[-20] - 100\n",
    "    else:\n",
    "        constant = constant_value\n",
    "    # The RGB format for cv2 is\n",
    "    filter_img = np.zeros((A.shape[0], A.shape[1], 3), np.uint8)\n",
    "    # Make filter_img be mask array\n",
    "    filter_img[A <= constant] = (0, 0, 0)\n",
    "    filter_img[A > constant] = (255, 255, 255)\n",
    "    # convert mask array to gray image format\n",
    "    gray_image = cv2.cvtColor(filter_img, cv2.COLOR_RGB2GRAY)\n",
    "    # findContours\n",
    "    # _, contours, _ = cv2.findContours(gray_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    # _, contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    _, contours, _ = cv2.findContours(gray_image, ContourRetrievalMode, cv2.CHAIN_APPROX_NONE)\n",
    "    # return contours (list of np.array) and constant (you assume they are almsot highest)\n",
    "    return (contours, constant)\n",
    "def get_rect_infos_and_center_pts(contours, h_min=13, w_min=13, h_max=19, w_max=19):\n",
    "    app_center_pts = []\n",
    "    rect_infos = []\n",
    "    for contour in contours:\n",
    "        # Step 2. make useful information\n",
    "        i = contour\n",
    "        con = i.reshape(i.shape[0], i.shape[2])\n",
    "        x_min = con[:, 0].min()\n",
    "        x_max = con[:, 0].max()\n",
    "        x_mean = con[:, 0].mean()\n",
    "        y_min = con[:, 1].min()\n",
    "        y_max = con[:, 1].max()\n",
    "        y_mean = con[:, 1].mean()\n",
    "        h = y_max - y_min\n",
    "        w = x_max - x_min\n",
    "        x_mean = int(x_mean)\n",
    "        y_mean = int(y_mean)\n",
    "        rect_info = [(x_min, x_max, y_min, y_max), (w, h), (x_mean, y_mean)]\n",
    "        # if h >= 13 and h < 19 and w >= 13 and h < 19:\n",
    "        if h >= h_min and h < h_max and w >= w_min and w < w_max:\n",
    "            cen_pt = [x_mean, y_mean]\n",
    "            app_center_pts.append(cen_pt)\n",
    "        else:\n",
    "            # print('(h={},{} , w={},{})'.format(h_max, h_min, w_max, w_min))\n",
    "            # print('Not matching ! rect_info = ', rect_info)\n",
    "            pass\n",
    "        # print(rect_info)\n",
    "        rect_infos.append(rect_info)\n",
    "    sorted_app_center_pts = sorted(app_center_pts, key=lambda cen_pt: cen_pt[0], reverse=False)\n",
    "    return (sorted_app_center_pts, rect_infos, app_center_pts)\n",
    "def get_2level_max_contours(img, gray_img):\n",
    "    def get_max_contours_by_filter_img(A, filter_img, ContourRetrievalMode=cv2.RETR_TREE):\n",
    "        # gray_image = cv2.cvtColor(filter_img, cv2.COLOR_RGB2GRAY)\n",
    "        gray_image = filter_img\n",
    "        # findContours\n",
    "        # _, contours, _ = cv2.findContours(gray_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        # _, contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        _, contours, _ = cv2.findContours(gray_image, ContourRetrievalMode, cv2.CHAIN_APPROX_NONE)\n",
    "        return contours\n",
    "\n",
    "    def get_max_contours(A, constant_value=None, ContourRetrievalMode=cv2.RETR_TREE):\n",
    "        constant = None\n",
    "        if constant_value == None:\n",
    "            # Algoruthm to find constant value\n",
    "            data = A.ravel()\n",
    "            sorted_data = np.copy(data)\n",
    "            sorted_data.sort()\n",
    "            constant = sorted_data[-20] - 100\n",
    "\n",
    "        else:\n",
    "            constant = constant_value\n",
    "        # The RGB format for cv2 is\n",
    "        filter_img = np.zeros((A.shape[0], A.shape[1], 3), np.uint8)\n",
    "        # Make filter_img be mask array\n",
    "        filter_img[A <= constant] = (0, 0, 0)\n",
    "        filter_img[A > constant] = (255, 255, 255)\n",
    "        # convert mask array to gray image format\n",
    "        gray_image = cv2.cvtColor(filter_img, cv2.COLOR_RGB2GRAY)\n",
    "        # findContours\n",
    "        # RETR_TREE will show the contour included in contour\n",
    "        # _, contours, _ = cv2.findContours(gray_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        # _, contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        _, contours, _ = cv2.findContours(gray_image, ContourRetrievalMode, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        # RETR_EXTERNAL will NOT show the contour inclued in contour\n",
    "        # _, contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        # return contours (list of np.array) and constant (you assume they are almsot highest)\n",
    "        return (contours, constant)\n",
    "\n",
    "    def get_minimum_rect_from_contours(contours, padding=2):\n",
    "        rect = (x_min, x_max, y_min, y_max) = (0, 0, 0, 0)\n",
    "        is_first = True\n",
    "        for contour in contours:\n",
    "            reshaped_contour = contour.reshape(contour.shape[0], contour.shape[2])\n",
    "            for pt in reshaped_contour:\n",
    "                x = pt[0]\n",
    "                y = pt[1]\n",
    "                if is_first == True:\n",
    "                    x_min = x\n",
    "                    x_max = x\n",
    "                    y_min = y\n",
    "                    y_max = y\n",
    "                    is_first = False\n",
    "                else:\n",
    "                    if x < x_min:\n",
    "                        x_min = x\n",
    "                    if x > x_max:\n",
    "                        x_max = x\n",
    "                    if y < y_min:\n",
    "                        y_min = y\n",
    "                    if y > y_max:\n",
    "                        y_max = y\n",
    "        x_min -= padding\n",
    "        x_max += padding\n",
    "        y_min -= padding\n",
    "        y_max += padding\n",
    "        rect = (x_min, x_max, y_min, y_max)\n",
    "        return rect\n",
    "\n",
    "    def is_point_in_rect(pt, rect=(0, 0, 0, 0)):\n",
    "        (x_min, x_max, y_min, y_max) = rect\n",
    "        x = pt[0]\n",
    "        y = pt[1]\n",
    "        if x >= x_min and x < x_max and y >= y_min and y < y_max:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_contour_in_rect(contour, rect=(0, 0, 0, 0)):\n",
    "        (x_min, x_max, y_min, y_max) = rect\n",
    "        isContourInRect = True\n",
    "        reshaped_contour = contour.reshape(contour.shape[0], contour.shape[2])\n",
    "        for pt in reshaped_contour:\n",
    "            if False == is_point_in_rect(pt, rect):\n",
    "                isContourInRect = False\n",
    "                break\n",
    "        return isContourInRect\n",
    "\n",
    "    def is_just_found_3_contained_contour(contours):\n",
    "        # contained_countour is mean a contour which continaed by some large contour\n",
    "        contained_contour_num = 0\n",
    "        contained_contours = []\n",
    "        for idx, contour in enumerate(contours):\n",
    "            other_contours = copy.deepcopy(contours)\n",
    "            other_contours.pop(idx)  # remove the contour in other_contours\n",
    "            is_contour_to_be_contained = False\n",
    "            for large_contour in other_contours:\n",
    "                rect = (min_x, max_x, min_y, max_y) = get_minimum_rect_from_contours([large_contour], padding=0)\n",
    "                if is_contour_in_rect(contour, rect):\n",
    "                    is_contour_to_be_contained = True\n",
    "                    contained_contours.append(contour)\n",
    "                    break\n",
    "            if is_contour_to_be_contained == True:\n",
    "                contained_contour_num = contained_contour_num + 1\n",
    "        if contained_contour_num == 3:\n",
    "            return (True, contained_contours)\n",
    "        else:\n",
    "            return (False, None)\n",
    "\n",
    "    # When two applicator touch together,\n",
    "    # inner contour case of level1_contour is better one case of then level2_contour\n",
    "\n",
    "    # When middle applicator cutting,\n",
    "    # inner contour case of level2_contour is better one case of then level1_contour\n",
    "\n",
    "    # So, how to decide which case is for use between these two cases both touching and middle cutting?\n",
    "    # and then we can process it easily after decision.\n",
    "\n",
    "    (level1_contours, constant) = get_max_contours(img, ContourRetrievalMode=cv2.RETR_TREE)\n",
    "    print('shape of level1_contours[0] = ', level1_contours[0].shape)\n",
    "    is_just_found_3_contained_contour(level1_contours)\n",
    "    (is_found, contained_contours) = is_just_found_3_contained_contour(level1_contours)\n",
    "    if is_found:\n",
    "        print('This is case of two applicator touched together (maybe)')\n",
    "        return contained_contours\n",
    "\n",
    "    # the remain case is process the middle-cut problem\n",
    "\n",
    "    (x_min, x_max, y_min, y_max) = get_minimum_rect_from_contours(level1_contours, padding=2)\n",
    "\n",
    "    threshed_im = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, -22)\n",
    "    filter_img = threshed_im\n",
    "    level2_contours = get_max_contours_by_filter_img(img, filter_img)\n",
    "\n",
    "    # level1_contours make a rectangle scope. Then select leve2 contour which is in this rectangle scope.\n",
    "    filtered_level2_contours = []\n",
    "    for contour in level2_contours:\n",
    "        if True == is_contour_in_rect(contour, rect=(x_min, x_max, y_min, y_max)):\n",
    "            filtered_level2_contours.append(contour)\n",
    "\n",
    "    (is_found, contained_contours) = is_just_found_3_contained_contour(filtered_level2_contours)\n",
    "    if is_found == True:\n",
    "        return contained_contours\n",
    "    else:\n",
    "        print('we cannot found our expected case, please see data to process different case')\n",
    "        return None\n",
    "\n",
    "    return filtered_level2_contours\n",
    "def get_contours_of_first_slice_in_special_case(first_slice_dict):\n",
    "    def convert_to_gray_image(pixel_array):\n",
    "        img = np.copy(pixel_array)\n",
    "        # Convert to float to avoid overflow or underflow losses.\n",
    "        img_2d = img.astype(float)\n",
    "        # Rescaling grey scale between 0-255\n",
    "        img_2d_scaled = (np.maximum(img_2d, 0) / img_2d.max()) * 255.0\n",
    "        # Convert to uint\n",
    "        img_2d_scaled = np.uint8(img_2d_scaled)\n",
    "        return img_2d_scaled\n",
    "\n",
    "    def get_gray_img_of_slice_dict(slice_dict):\n",
    "        img = slice_dict['rescale_pixel_array']\n",
    "        gray_img = convert_to_gray_image(img)\n",
    "        return gray_img\n",
    "\n",
    "    img = first_slice_dict['rescale_pixel_array']\n",
    "    gray_img = get_gray_img_of_slice_dict(first_slice_dict)\n",
    "    contours = get_2level_max_contours(img, gray_img)\n",
    "    return contours\n",
    "\n",
    "    pass\n",
    "def get_app_center_pts_of_first_slice(first_slice_dict):\n",
    "    ps_x = first_slice_dict['PixelSpacing_x']\n",
    "    ps_y = first_slice_dict['PixelSpacing_y']\n",
    "    h_max = int((19.0 * 4.19921e-1) / ps_y)\n",
    "    h_min = int((13.0 * 4.19921e-1) / ps_y)\n",
    "    w_max = int((19.0 * 4.19921e-1) / ps_x)\n",
    "    w_min = int((13.0 * 4.19921e-1) / ps_x)\n",
    "    # print('(h={},{} , w={},{})'.format(h_max, h_min, w_max, w_min))\n",
    "\n",
    "    (contours, constant) = get_max_contours(first_slice_dict['rescale_pixel_array'])\n",
    "\n",
    "    # (sorted_app_center_pts, rect_infos, app_center_pts) = get_rect_infos_and_center_pts(contours)\n",
    "    (sorted_app_center_pts, rect_infos, app_center_pts) = get_rect_infos_and_center_pts(contours, h_max=h_max,\n",
    "                                                                                        h_min=h_min, w_max=w_max,\n",
    "                                                                                        w_min=w_min)\n",
    "    print('\\n\\n')\n",
    "    print(sorted_app_center_pts)\n",
    "    # TODO After researching done, write the code to finish this task\n",
    "    if sorted_app_center_pts == None or len(sorted_app_center_pts) != 3:\n",
    "        contours = get_contours_of_first_slice_in_special_case(first_slice_dict)\n",
    "        if len(contours) != 3:\n",
    "            print('Error process for special case of first slice')\n",
    "        (sorted_app_center_pts, rect_infos, app_center_pts) = get_rect_infos_and_center_pts(contours, h_max=h_max,\n",
    "                                                                                            h_min=0, w_max=w_max,\n",
    "                                                                                            w_min=0)\n",
    "        x_sorted_pts = sorted(app_center_pts, key=lambda cen_pt: cen_pt[0], reverse=False)\n",
    "        return x_sorted_pts\n",
    "        pass\n",
    "    print('\\n\\n')\n",
    "\n",
    "    x_sorted_pts = sorted(app_center_pts, key=lambda cen_pt: cen_pt[0], reverse=False)\n",
    "    print('get_app_center_pts_of_first_slice() -> x_sorted_pts = ', x_sorted_pts)\n",
    "    return x_sorted_pts\n",
    "    pass\n",
    "def get_view_scope_by_slice(first_slice_dict, padding=30):\n",
    "    (contours, constant) = get_max_contours(first_slice_dict['rescale_pixel_array'])\n",
    "    print('PixelSpacing_(x,y)=({}, {})'.format(first_slice_dict['PixelSpacing_x'], first_slice_dict['PixelSpacing_y']))\n",
    "    ps_x = first_slice_dict['PixelSpacing_x']\n",
    "    ps_y = first_slice_dict['PixelSpacing_y']\n",
    "    h_max = int((19.0 * 4.19921e-1) / ps_y)\n",
    "    h_min = int((13.0 * 4.19921e-1) / ps_y)\n",
    "    w_max = int((19.0 * 4.19921e-1) / ps_x)\n",
    "    w_min = int((13.0 * 4.19921e-1) / ps_x)\n",
    "    print('(h={},{} , w={},{})'.format(h_max, h_min, w_max, w_min))\n",
    "\n",
    "    # (sorted_app_center_pts, rect_infos, app_center_pts) = get_rect_infos_and_center_pts(contours)\n",
    "    (sorted_app_center_pts, rect_infos, app_center_pts) = get_rect_infos_and_center_pts(contours, h_max=h_max,\n",
    "                                                                                        w_max=w_max, h_min=h_min,\n",
    "                                                                                        w_min=w_min)\n",
    "    print('sorted_app_center_pts = ', sorted_app_center_pts)\n",
    "    if sorted_app_center_pts == None or len(sorted_app_center_pts) != 3:\n",
    "        contours = get_contours_of_first_slice_in_special_case(first_slice_dict)\n",
    "        if len(contours) != 3:\n",
    "            print('Error process for special case of first slice')\n",
    "        (sorted_app_center_pts, rect_infos, app_center_pts) = get_rect_infos_and_center_pts(contours, h_max=h_max,\n",
    "                                                                                            h_min=0, w_max=w_max,\n",
    "                                                                                            w_min=0)\n",
    "        padding = padding + 30\n",
    "\n",
    "    x_sorted_pts = sorted(app_center_pts, key=lambda cen_pt: cen_pt[0], reverse=False)\n",
    "    y_sorted_pts = sorted(app_center_pts, key=lambda cen_pt: cen_pt[1], reverse=False)\n",
    "\n",
    "    (min_x, max_x) = (x_sorted_pts[0][0], x_sorted_pts[-1][0])\n",
    "    (min_y, max_y) = (y_sorted_pts[0][1], y_sorted_pts[-1][1])\n",
    "    print('X:({}, {})'.format(min_x, max_x))\n",
    "    print('Y:({}, {})'.format(min_y, max_y))\n",
    "    # Print information\n",
    "    # [[228, 324], [264, 334], [299, 347]]\n",
    "    # X:(228, 299)\n",
    "    # Y:(324, 347)\n",
    "    w = max_x - min_x\n",
    "    h = max_y - min_y\n",
    "    dist = np.max([w, h])\n",
    "    cen_x = int(min_x + (w) / 2)\n",
    "    cen_y = int(min_y + (h) / 2)\n",
    "    loc_min_x = int(cen_x - dist / 2)\n",
    "    loc_max_x = int(cen_x + dist / 2)\n",
    "    loc_min_y = int(cen_y - dist / 2)\n",
    "    loc_max_y = int(cen_y + dist / 2)\n",
    "    print('loc X:({}, {})'.format(loc_min_x, loc_max_x))\n",
    "    print('loc Y:({}, {})'.format(loc_min_y, loc_max_y))\n",
    "    # padding = 30 #Suitable value for no center point?\n",
    "\n",
    "    # loc X:(227, 298)\n",
    "    # loc Y:(299, 370)\n",
    "    # And We have gray_img = gray_img[270:390, 200:320]\n",
    "    # So it should be\n",
    "    # gray_img = gray_img[ loc_min_y-padding: loc_max_y+padding, loc_min_x-padding:loc_max_x+padding]\n",
    "    view_min_y = loc_min_y - padding\n",
    "    view_max_y = loc_max_y + padding\n",
    "    view_min_x = loc_min_x - padding\n",
    "    view_max_x = loc_max_x + padding\n",
    "    return (view_min_y, view_max_y, view_min_x, view_max_x)\n",
    "    # The way to use return value is\n",
    "    # gray_img = gray_img[ view_min_y: view_max_y, view_min_x:view_max_x]\n",
    "\n",
    "def distance(pt1, pt2):\n",
    "    axis_num = len(pt1)\n",
    "    sum = 0.0\n",
    "    for idx in range(axis_num):\n",
    "        sum = sum + (pt1[idx] - pt2[idx]) ** 2\n",
    "    ans = math.sqrt(sum)\n",
    "    return ans\n",
    "def get_most_closed_pt(src_pt, pts, allowed_distance=100):\n",
    "    if pts == None:\n",
    "        return None\n",
    "    if pts == []:\n",
    "        return None\n",
    "    dst_pt = None\n",
    "    for pt in pts:\n",
    "        if distance(src_pt, pt) > allowed_distance:\n",
    "            # the point , whoes distance with src_pt < allowed_distance, cannot join this loop\n",
    "            continue\n",
    "\n",
    "        if dst_pt == None:\n",
    "            dst_pt = pt\n",
    "        else:\n",
    "            if distance(src_pt, pt) < distance(src_pt, dst_pt):\n",
    "                dst_pt = pt\n",
    "        pass\n",
    "    return dst_pt\n",
    "def make_lines_process(app_pts):\n",
    "    lines = [[], [], []]\n",
    "    sorted_app_pts_keys = sorted(app_pts.keys())\n",
    "    print(sorted_app_pts_keys)\n",
    "\n",
    "    for key_idx in range(len(sorted_app_pts_keys)):\n",
    "        key = sorted_app_pts_keys[key_idx]\n",
    "        pts = app_pts[key]\n",
    "\n",
    "        if key_idx == 0:\n",
    "            lines[0].append(pts[0])\n",
    "            lines[1].append(pts[1])\n",
    "            lines[2].append(pts[2])\n",
    "        else:\n",
    "            for line in lines:\n",
    "                last_line_pt = line[-1]\n",
    "                if last_line_pt == None:\n",
    "                    continue\n",
    "                last_line_pt_x = last_line_pt[0]\n",
    "\n",
    "                candidate_pt = None\n",
    "                # looking forward for candidate_pt\n",
    "                for pt_idx in range(len(pts)):\n",
    "                    pt = pts[pt_idx]\n",
    "                    pt_x = pt[0]\n",
    "                    ##if abs(last_line_pt_x - pt_x) < 5\n",
    "                    # if abs(last_line_pt_x - pt_x) < 5 or (lines[0][-1] == None and lines[2][-1] == None):\n",
    "                    if abs(last_line_pt_x - pt_x) < 10:\n",
    "                        if candidate_pt == None:\n",
    "                            candidate_pt = pt\n",
    "                        else:\n",
    "                            candidate_pt_x = candidate_pt[0]\n",
    "                            if abs(candidate_pt_x - last_line_pt_x) > abs(pt_x - last_line_pt_x):\n",
    "                                candidate_pt = last_line_pt\n",
    "                line.append(candidate_pt)\n",
    "                # the data structure fo each line will be like\n",
    "                # [(x0,y0,z0), (x1,y1,z1), ... ,(xn,yn,zn),None]\n",
    "\n",
    "    # clean dummy None in last element in each line\n",
    "    for idx in range(len(lines)):\n",
    "        line = lines[idx]\n",
    "        line = line[:-1]\n",
    "        lines[idx] = line\n",
    "    return lines\n",
    "\n",
    "def algo_run_by_folder(folder):\n",
    "    # app_pts_dict[z] = [[x,y,z], [x,y,z], [x,y,z] ]\n",
    "    app_pts_dict = {}\n",
    "    ct_filelist = get_ct_filelist_by_folder(folder)\n",
    "    ct_dicom_dict = gen_ct_dicom_dict(ct_filelist)\n",
    "    sorted_ct_dicom_dict_keys = sorted(ct_dicom_dict['SliceLocation'].keys())\n",
    "    first_slice_dict = ct_dicom_dict['SliceLocation'][sorted_ct_dicom_dict_keys[0]]\n",
    "    based_center_pts = get_app_center_pts_of_first_slice(first_slice_dict)\n",
    "    if len(based_center_pts) != 3:\n",
    "        print('len(based_center_pts) is wrong, folder = ', folder)\n",
    "        return\n",
    "    else:\n",
    "        print(based_center_pts)\n",
    "\n",
    "    first_slice_dict['data'] = {}\n",
    "    first_slice_dict['data']['center_pts'] = based_center_pts\n",
    "    (view_min_y, view_max_y, view_min_x, view_max_x) = get_view_scope_by_slice(first_slice_dict, padding=100)\n",
    "    \n",
    "    prev_slice_dict = None\n",
    "    for z in sorted_ct_dicom_dict_keys:\n",
    "        app_pts_dict[z] = []\n",
    "        slice_dict = ct_dicom_dict['SliceLocation'][z]\n",
    "        if 'data' not in slice_dict.keys():\n",
    "            slice_dict['data'] = {}\n",
    "        slice_dict['data']['prev_slice_dict'] = prev_slice_dict\n",
    "        print('z = ', z, 'filepath = ', slice_dict['filepath'])\n",
    "\n",
    "        if 'data' in slice_dict and 'center_pts' in slice_dict['data']:\n",
    "            prev_slice_dict = slice_dict\n",
    "            # pure_show_slice_dict(slice_dict, (view_min_y, view_max_y, view_min_x, view_max_x))\n",
    "            # First slice\n",
    "            print('center_pts = ', slice_dict['data']['center_pts'])\n",
    "            for pt in slice_dict['data']['center_pts']:\n",
    "                x = pt[0]\n",
    "                y = pt[1]\n",
    "                app_pts_dict[z].append([x, y, z])\n",
    "            continue\n",
    "\n",
    "        img = slice_dict['rescale_pixel_array']\n",
    "        gray_img = convert_to_gray_image(img)\n",
    "        # fig = plt.figure(figsize=(20, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "        # threshed_im = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, -22)\n",
    "        gray_img = gray_img[view_min_y: view_max_y, view_min_x:view_max_x]\n",
    "        img = img[view_min_y: view_max_y, view_min_x:view_max_x]\n",
    "\n",
    "        # threshed_im = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, -22)\n",
    "        # threshed_im = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5, 7)\n",
    "        threshed_im = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, -22)\n",
    "        # I'm not sure why it is the perfect value in our case.\n",
    "\n",
    "        # plt.subplot(1, 4, 1)\n",
    "        # plt.imshow(threshed_im, cmap=plt.cm.bone)\n",
    "        # plt.subplot(1, 4, 2)\n",
    "        # plt.imshow(img, cmap=plt.cm.bone)\n",
    "        # plt.subplot(1, 4, 3)\n",
    "        # plt.imshow(gray_img, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "        filter_img = threshed_im\n",
    "        # contours = get_max_contours_by_filter_img(img, filter_img)\n",
    "\n",
    "        # contours = get_max_contours_by_filter_img(img, filter_img, ContourRetrievalMode=cv2.RETR_TREE)\n",
    "        # (contours_without_filter,constant) = get_max_contours(img, ContourRetrievalMode=cv2.RETR_TREE)\n",
    "        # proc_img = np.copy(img)\n",
    "        # contours.extend(contours_without_filter)\n",
    "\n",
    "        contours = get_max_contours_by_filter_img(img, filter_img, ContourRetrievalMode=cv2.RETR_TREE)\n",
    "\n",
    "        (contours_without_filter, constant) = get_max_contours(img, ContourRetrievalMode=cv2.RETR_TREE)\n",
    "        contours.extend(contours_without_filter)\n",
    "\n",
    "        (contours_without_filter, constant) = get_max_contours(img, ContourRetrievalMode=cv2.RETR_EXTERNAL)\n",
    "        contours.extend(contours_without_filter)\n",
    "\n",
    "        the_contours = get_max_contours_by_filter_img(img, filter_img, ContourRetrievalMode=cv2.RETR_EXTERNAL)\n",
    "        contours.extend(the_contours)\n",
    "\n",
    "        proc_img = np.copy(img)\n",
    "        contours.extend(contours_without_filter)\n",
    "\n",
    "        ellipse_center_pts = []\n",
    "        draw_ellipse_center_pts = []\n",
    "        for contour in contours:\n",
    "            if len(contour) < 5:\n",
    "                # You need at least 5 points in contour, so that you can use fitEllipse\n",
    "\n",
    "                reshape_contour = contour.reshape(contour.shape[0], contour.shape[2])\n",
    "                xs = [pt[0] for pt in reshape_contour]\n",
    "                ys = [pt[1] for pt in reshape_contour]\n",
    "                x = int((min(xs) + max(xs)) / 2)\n",
    "                y = int((min(ys) + max(ys)) / 2)\n",
    "                # enablePrint()\n",
    "                # print(\"special fitEllipse(x,y) = ({},{})\".format(x,y))\n",
    "                # blockPrint()\n",
    "                ellipse_center_pts.append([x, y])\n",
    "                continue\n",
    "            ellipse = cv2.fitEllipse(contour)  # auto-figure the ellipse to fit contour\n",
    "            # print(ellipse)\n",
    "            ellipse_poly = cv2.ellipse2Poly((int(ellipse[0][0]), int(ellipse[0][1])),\n",
    "                                            (int(ellipse[1][0] / 2), int(ellipse[1][1] / 2)), int(ellipse[2]), 0, 360,\n",
    "                                            5)\n",
    "            draw_x = int(ellipse[0][0])\n",
    "            draw_y = int(ellipse[0][1])\n",
    "            draw_ellipse_center_pts.append([draw_x, draw_y])\n",
    "            x = int(ellipse[0][0]) + view_min_x\n",
    "            y = int(ellipse[0][1]) + view_min_y\n",
    "            ellipse_center_pts.append([x, y])\n",
    "            reshape_poly = ellipse_poly.reshape(ellipse_poly.shape[0], 1, ellipse_poly.shape[1])\n",
    "            cv2.drawContours(proc_img, reshape_poly, -1, (255, 0, 0), 1)\n",
    "            # cv2.line(proc_img,(draw_x,draw_y),(draw_x,draw_y),(255,0,0),3)\n",
    "\n",
    "        figure_center_pts = []\n",
    "        for pt in prev_slice_dict['data']['center_pts']:\n",
    "            if len(prev_slice_dict['data']['center_pts']) == 1:\n",
    "                eval_pt = pt\n",
    "                pp_slice_dict = prev_slice_dict['data']['prev_slice_dict']\n",
    "                # pp_slice_dict is prev_prev_slice_dict\n",
    "                # if prev_prev_slice_dict != None and len(prev_prev_slice_dict['data']['center_pts'])==1:\n",
    "                if pp_slice_dict != None and len(pp_slice_dict['data']['center_pts']) == 1:\n",
    "                    # prev_prev_pt = prev_prev_slice_dict['data']['center_pts'][0]\n",
    "                    pp_pt = pp_slice_dict['data']['center_pts'][0]\n",
    "                    prev_pt = prev_slice_dict['data']['center_pts'][0]\n",
    "                    eval_pt[0] = eval_pt[0] + (prev_pt[0] - pp_pt[0])\n",
    "                    eval_pt[1] = eval_pt[1] + (prev_pt[1] - pp_pt[1])\n",
    "                    print('update eval_pt = {}', eval_pt)\n",
    "                    ps_x = slice_dict['PixelSpacing_x']\n",
    "                    ps_y = slice_dict['PixelSpacing_y']\n",
    "                    # print(\"(ps_x, ps_y) = ({},{})\".format(ps_x,ps_y))\n",
    "                    a_distance_mm = 15.0\n",
    "                    a_distance = int(a_distance_mm / ps_x)\n",
    "                dst_pt = get_most_closed_pt(eval_pt, ellipse_center_pts, allowed_distance=a_distance)\n",
    "            else:\n",
    "                ps_x = slice_dict['PixelSpacing_x']\n",
    "                ps_y = slice_dict['PixelSpacing_y']\n",
    "                # print(\"(ps_x, ps_y) = ({},{})\".format(ps_x,ps_y))\n",
    "                a_distance_mm = 10.0\n",
    "                a_distance = int(a_distance_mm / ps_x)\n",
    "                dst_pt = get_most_closed_pt(pt, ellipse_center_pts, allowed_distance=a_distance)\n",
    "            if dst_pt != None:\n",
    "                print('dst_pt != None with dst_pt = ({},{})'.format(dst_pt[0], dst_pt[1]))\n",
    "                figure_center_pts.append(dst_pt)\n",
    "            else:\n",
    "                print('dst_pt == None with pt = ({},{})'.format(pt[0], pt[1]))\n",
    "\n",
    "        if 'data' not in slice_dict.keys():\n",
    "            slice_dict['data'] = {}\n",
    "        slice_dict['data']['center_pts'] = figure_center_pts\n",
    "\n",
    "        print('ellipse_center_pts = ', ellipse_center_pts)\n",
    "        print('center_pts = ', slice_dict['data']['center_pts'])\n",
    "\n",
    "        # plt.subplot(1, 4, 4)\n",
    "        for [x, y] in figure_center_pts:\n",
    "            app_pts_dict[z].append([x, y, z])\n",
    "            draw_x = x - view_min_x\n",
    "            draw_y = y - view_min_y\n",
    "            cv2.line(proc_img, (draw_x, draw_y), (draw_x, draw_y), (255, 0, 0), 3)\n",
    "\n",
    "        # plt.subplot(1, 4, 4)\n",
    "        # plt.imshow(proc_img, cmap=plt.cm.bone)\n",
    "        # plt.show()\n",
    "        prev_slice_dict = slice_dict\n",
    "    print(app_pts_dict)\n",
    "    return app_pts_dict\n",
    "\n",
    "\n",
    "# Implementation of get_metric_pt_info_by_travel_distance(metric_line, pt_idx, pt_idx_remainder, travel_dist)\n",
    "\n",
    "# REWRITE get_metric_pt_info_by_travel_distance, so the get_metric_pt, reduct_distance_step and get_metric_pt_info_travel_distance will not be USED\n",
    "def get_metric_pt(metric_line, pt_idx, pt_idx_remainder):\n",
    "    # print('get_metric_pt(metric_line={}, pt_idx={}, pt_idx_remainder={})'.format(metric_line, pt_idx, pt_idx_remainder))\n",
    "    pt = metric_line[pt_idx].copy()\n",
    "    try:\n",
    "        if (pt_idx + 1 >= len(metric_line)):\n",
    "            end_pt = metric_line[pt_idx]\n",
    "        else:\n",
    "            end_pt = metric_line[pt_idx + 1]\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print('EEEEEE')\n",
    "        print('pt_idx = {}'.format(pt_idx))\n",
    "        print('pt_idx_remainder = {}'.format(pt_idx_remainder))\n",
    "        print('metric_line[{}] = {}'.format(pt_idx, metric_line[pt_idx]))\n",
    "        raise\n",
    "\n",
    "    for axis_idx in range(3):\n",
    "        # diff = end_pt[axis_idx] - pt[axis_idx]\n",
    "        # diff_with_ratio = diff * pt_idx_remainder\n",
    "        # print('axis_idx = {} ->  diff_with_ratio = {}'.format(axis_idx, diff_with_ratio) )\n",
    "        pt[axis_idx] += ((end_pt[axis_idx] - pt[axis_idx]) * pt_idx_remainder)\n",
    "        # pt[axis_idx] = pt[axis_idx] + diff_with_ratio\n",
    "    return pt\n",
    "def reduce_distance_step(metric_line, pt_idx, pt_idx_remainder, dist):\n",
    "    # reduce dist and move further more step for (pt_idx, pt_idx_remainder)\n",
    "    # ret_dist = ??  reduce dist into ret_dist\n",
    "    # Just implement code here , so that the data move a little distance. (mean reduce dist and move more)\n",
    "\n",
    "    start_pt_idx = pt_idx\n",
    "    start_pt_idx_remainder = pt_idx_remainder\n",
    "    start_pt = get_metric_pt(metric_line, start_pt_idx, start_pt_idx_remainder)\n",
    "\n",
    "    # To figure out what distance we perfer to reduce in this step\n",
    "    # And the idea is seperate int to two case\n",
    "    if start_pt_idx < len(metric_line) - 1:\n",
    "        # CASE: there is a next pt_idx for start_pt_idx\n",
    "        # In this case, we let end_pt_idx be the next pt_idx of start_pt_idx\n",
    "        # So it start_pt_idx +1. and don't forget to reset remainder in to zero\n",
    "        end_pt_idx = start_pt_idx + 1\n",
    "        end_pt_idx_remainder = 0\n",
    "\n",
    "    else:\n",
    "        # CASE there is no any next _pt_idx for start_pt_idx\n",
    "        # In this case, we let end_pt_idx point to end idx of line and let remainder be in maximum value (1.0)\n",
    "        # So the end_pt with idx and remainder can represent the most far point in the metric line.\n",
    "        end_pt_idx = start_pt_idx\n",
    "        end_pt_idx_remainder = 1\n",
    "\n",
    "    end_pt = get_metric_pt(metric_line, end_pt_idx, end_pt_idx_remainder)\n",
    "    max_reducable_dist = distance(start_pt, end_pt)  # max_reducable_dist in this iteration\n",
    "\n",
    "    # We have start_pt and end_pt , and we have the dist value\n",
    "    # So we can try to walk from start_pt to some point which belong to [start_pt, end_pt)\n",
    "    # There are two cases for this walking\n",
    "    # CASE 1: the end_pt is not enough to walking dist , so just walking to the end_pt\n",
    "    # CASE 2: the end_pt is enough and we just need to figure where to stop between [start_pt, end_pt)\n",
    "    # PS: 'is enough' is mean distance will be reduced to zero, so the end of travel is in  [start_pt, end_pt)\n",
    "    if dist > max_reducable_dist:  # CASE 1 the end_pt is not enough to walking dist\n",
    "        dist_after_walking = dist - max_reducable_dist\n",
    "        walking_stop_pt_idx = end_pt_idx\n",
    "        walking_stop_pt_idx_remainder = end_pt_idx_remainder\n",
    "        # return (dist, end_pt_idx, end_pt_idx_remainder)\n",
    "        return (dist_after_walking, walking_stop_pt_idx, walking_stop_pt_idx_remainder)\n",
    "    else:  # CASE 2 the end_pt is enough, so walking_stop_pt is between [start_pt, end_pt)\n",
    "        walking_stop_pt_idx = start_pt_idx\n",
    "\n",
    "        # Figure out walking_stop_pt_idx_remainder\n",
    "        segment_dist = distance(start_pt, end_pt)\n",
    "        ratio = dist / segment_dist\n",
    "        walking_stop_pt_idx_remainder = start_pt_idx_remainder + (1 - start_pt_idx_remainder) * ratio\n",
    "\n",
    "        dist_after_walking = 0\n",
    "        return (dist_after_walking, walking_stop_pt_idx, walking_stop_pt_idx_remainder)\n",
    "\n",
    "    pass\n",
    "    # return (ret_dist, ret_pt_idx, ret_pt_idx_remainder)\n",
    "def get_metric_pt_info_by_travel_distance(metric_line, pt_idx, pt_idx_remainder, travel_dist):\n",
    "    dist = travel_dist\n",
    "    count_max = len(metric_line)\n",
    "    count = 0\n",
    "\n",
    "    while (True):\n",
    "        (t_dist, t_pt_idx, t_pt_idx_remainder) = reduce_distance_step(metric_line, pt_idx, pt_idx_remainder, dist)\n",
    "\n",
    "        if pt_idx == len(metric_line) - 1 and pt_idx_remainder == 1:\n",
    "            # CASE 0: This is mean the distanced point will out of the line\n",
    "            print('out of line and remaind unproces distance = ', t_dist)\n",
    "            t_pt = metric_line[-1].copy()\n",
    "            return (t_pt, t_pt_idx, t_pt_idx_remainder, t_dist)\n",
    "            break\n",
    "        if t_dist == 0:\n",
    "            # CASE 1: All distance have been reduced\n",
    "            t_pt = get_metric_pt(metric_line, t_pt_idx, t_pt_idx_remainder)\n",
    "            return (t_pt, t_pt_idx, t_pt_idx_remainder, t_dist)\n",
    "\n",
    "        count += 1\n",
    "        if count > count_max:\n",
    "            # CASE 2: over looping of what we expect. This is case of bug in my source code\n",
    "            print('The out of counting in loop is happended. this is a bug')\n",
    "            t_pt = get_metric_pt(metric_line, t_pt_idx, t_pt_idx_remainder)\n",
    "            return (t_pt, t_pt_idx, t_pt_idx_remainder, t_dist)\n",
    "        pt_idx = t_pt_idx\n",
    "        pt_idx_remainder = t_pt_idx_remainder\n",
    "        dist = t_dist\n",
    "\n",
    "# Useful\n",
    "def get_maps_with_folder(folder):\n",
    "    z_map = {}\n",
    "    ct_filepath_map = {}\n",
    "    ct_filelist = []\n",
    "    for file in os.listdir(folder):\n",
    "        ct_filepath = r\"{}/{}\".format(folder, file)\n",
    "        ct_fp = None\n",
    "        try:\n",
    "            ct_fp = pydicom.read_file(ct_filepath)\n",
    "            if ct_fp.Modality != 'CT':\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # print(ct_filepath)\n",
    "        ct_filelist.append(ct_filepath)\n",
    "\n",
    "        x_spacing, y_spacing = float(ct_fp.PixelSpacing[0]), float(ct_fp.PixelSpacing[1])\n",
    "        origin_x, origin_y, origin_z = ct_fp.ImagePositionPatient\n",
    "        # print(x_spacing, y_spacing)\n",
    "        # print(origin_x, origin_y, origin_z)\n",
    "\n",
    "        z_dict = {}\n",
    "        z_dict['ct_filepath'] = ct_filepath\n",
    "        z_dict['origin_x'] = origin_x\n",
    "        z_dict['origin_y'] = origin_y\n",
    "        z_dict['origin_z'] = origin_z\n",
    "        z_dict['x_spacing'] = x_spacing\n",
    "        z_dict['y_spacing'] = y_spacing\n",
    "\n",
    "        z_map[origin_z] = z_dict\n",
    "        ct_filepath_map[ct_filepath] = z_dict\n",
    "    return z_map, ct_filepath_map\n",
    "\n",
    "# The CT data is the format with 512 x 512, but we want to transfer it into real metric space\n",
    "def convert_lines_in_metrics(lines, ct_folder):\n",
    "\n",
    "    z_map, ct_filepath_map = get_maps_with_folder(ct_folder)\n",
    "    new_lines = []\n",
    "    for i in range(len(lines)):\n",
    "        new_lines.append([])\n",
    "\n",
    "    for line_idx in range(len(lines)):\n",
    "        line = lines[line_idx]\n",
    "        new_line = new_lines[line_idx]\n",
    "        for pt in line:\n",
    "            pt_z = pt[2]\n",
    "            z_dict = z_map[pt_z]\n",
    "            x_spacing = z_dict['x_spacing']\n",
    "            y_spacing = z_dict['y_spacing']\n",
    "            origin_x = z_dict['origin_x']\n",
    "            origin_y = z_dict['origin_y']\n",
    "            pt_x = pt[0]\n",
    "            pt_y = pt[1]\n",
    "            tmp_x = pt_x * x_spacing + origin_x\n",
    "            tmp_y = pt_y * y_spacing + origin_y\n",
    "            new_pt_x = float(Decimal(str(tmp_x)).quantize(Decimal('0.00')))  # Some format transfer stuff\n",
    "            new_pt_y = float(Decimal(str(tmp_y)).quantize(Decimal('0.00')))  # Some format transfer stuff\n",
    "            new_pt = [new_pt_x, new_pt_y, pt_z]\n",
    "            new_line.append(new_pt)\n",
    "    return new_lines\n",
    "def get_applicator_rp_line(metric_line, first_purpose_distance_mm, each_purpose_distance_mm):\n",
    "    tandem_rp_line = []\n",
    "    pt_idx = 0\n",
    "    pt_idx_remainder = 0\n",
    "    travel_dist = first_purpose_distance_mm\n",
    "    (t_pt, t_pt_idx, t_pt_idx_remainder, t_dist) = get_metric_pt_info_by_travel_distance(metric_line, pt_idx,pt_idx_remainder, travel_dist)\n",
    "    tandem_rp_line.append(t_pt)\n",
    "    for i in range(100):\n",
    "        travel_dist = each_purpose_distance_mm\n",
    "        (pt_idx, pt_idx_remainder) = (t_pt_idx, t_pt_idx_remainder)\n",
    "        (t_pt, t_pt_idx, t_pt_idx_remainder, t_dist) = get_metric_pt_info_by_travel_distance(metric_line, pt_idx,pt_idx_remainder,travel_dist)\n",
    "        if (t_pt == tandem_rp_line[-1]):\n",
    "            break\n",
    "        tandem_rp_line.append(t_pt)\n",
    "\n",
    "    return tandem_rp_line\n",
    "\n",
    "\n",
    "def wrap_to_rp_file(RP_OperatorsName, rs_filepath, tandem_rp_line, out_rp_filepath, lt_ovoid_rp_line, rt_ovoid_rp_line):\n",
    "    rp_template_filepath = r'RP_Template/Brachy_RP.1.2.246.352.71.5.417454940236.2063186.20191015164204.dcm'\n",
    "    def get_new_uid(old_uid='1.2.246.352.71.5.417454940236.2063186.20191015164204', study_date='20190923'):\n",
    "        uid = old_uid\n",
    "        def gen_6_random_digits():\n",
    "            ret_str = \"\"\n",
    "            for i in range(6):\n",
    "                ch = chr(random.randrange(ord('0'), ord('9') + 1))\n",
    "                ret_str += ch\n",
    "            return ret_str\n",
    "        theStudyDate = study_date\n",
    "        uid_list = uid.split('.')\n",
    "        uid_list[-1] = theStudyDate + gen_6_random_digits()\n",
    "        new_uid = '.'.join(uid_list)\n",
    "        return new_uid\n",
    "\n",
    "    # Read RS file as input\n",
    "    rs_fp = pydicom.read_file(rs_filepath)\n",
    "    # read RP tempalte into rp_fp\n",
    "    rp_fp = pydicom.read_file(rp_template_filepath)\n",
    "\n",
    "    rp_fp.OperatorsName = RP_OperatorsName\n",
    "    rp_fp.PhysiciansOfRecord = rs_fp.PhysiciansOfRecord\n",
    "    rp_fp.FrameOfReferenceUID = rs_fp.ReferencedFrameOfReferenceSequence[0].FrameOfReferenceUID\n",
    "    rp_fp.ReferencedStructureSetSequence[0].ReferencedSOPClassUID = rs_fp.SOPClassUID\n",
    "    rp_fp.ReferencedStructureSetSequence[0].ReferencedSOPInstanceUID = rs_fp.SOPInstanceUID\n",
    "\n",
    "    directAttrSet = [\n",
    "        'PhysiciansOfRecord', 'PatientName', 'PatientID',\n",
    "        'PatientBirthDate', 'PatientBirthTime', 'PatientSex',\n",
    "        'DeviceSerialNumber', 'SoftwareVersions', 'StudyID',\n",
    "        'StudyDate', 'StudyTime', 'StudyInstanceUID']\n",
    "    for attr in directAttrSet:\n",
    "        #rs_val = getattr(rs_fp, attr)\n",
    "        #rp_val = getattr(rp_fp, attr)\n",
    "        #print('attr={}, \\n In RS->{} \\n In RP->{}'.format(attr, rs_val, rp_val))\n",
    "        val = getattr(rs_fp, attr)\n",
    "        setattr(rp_fp, attr, val)\n",
    "        #new_rp_val = getattr(rp_fp, attr)\n",
    "        #print('after update, RP->{}\\n'.format(new_rp_val))\n",
    "\n",
    "    newSeriesInstanceUID = get_new_uid(old_uid=rp_fp.SeriesInstanceUID, study_date=rp_fp.StudyDate)\n",
    "    newSOPInstanceUID = get_new_uid(old_uid=rp_fp.SOPInstanceUID, study_date=rp_fp.StudyDate)\n",
    "    rp_fp.SeriesInstanceUID = newSeriesInstanceUID\n",
    "    rp_fp.SOPInstanceUID = newSOPInstanceUID\n",
    "    rp_fp.InstanceCreationDate = rp_fp.RTPlanDate = rp_fp.StudyDate = rs_fp.StudyDate\n",
    "    rp_fp.RTPlanTime = str(float(rs_fp.StudyTime) + 0.001)\n",
    "    rp_fp.InstanceCreationTime = str(float(rs_fp.InstanceCreationTime) + 0.001)\n",
    "\n",
    "    # Clean Dose Reference\n",
    "    rp_fp.DoseReferenceSequence.clear()\n",
    "\n",
    "\n",
    "    # The template structure for applicator\n",
    "    # Tandem -> rp_fp.ApplicationSetupSequence[0].ChannelSequence[0]\n",
    "    # Rt Ovoid -> rp_fp.ApplicationSetupSequence[0].ChannelSequence[1]\n",
    "    # Lt OVoid -> rp_fp.ApplicationSetupSequence[0].ChannelSequence[2]\n",
    "    # For each applicator .NumberOfControlPoints is mean number of point\n",
    "    # For each applicator .BrachyControlPointSequence is mean the array of points\n",
    "\n",
    "\n",
    "    BCPItemTemplate = copy.deepcopy(rp_fp.ApplicationSetupSequence[0].ChannelSequence[0].BrachyControlPointSequence[0])\n",
    "    rp_lines = [tandem_rp_line, rt_ovoid_rp_line, lt_ovoid_rp_line]\n",
    "\n",
    "    #TODO rp_Ref_ROI_Numbers need to match to current RS's ROI number of three applicators\n",
    "    rp_Ref_ROI_Numbers = [16, 17, 18]\n",
    "    rp_ControlPointRelativePositions = [3.5, 3.5, 3.5]\n",
    "    for idx,rp_line in enumerate(rp_lines):\n",
    "        # Change ROINumber of RP_Template_TestData RS into output RP output file\n",
    "        # Do  I need to fit ROINumber in RS or not? I still have no answer\n",
    "        rp_fp.ApplicationSetupSequence[0].ChannelSequence[idx].ReferencedROINumber = rp_Ref_ROI_Numbers[idx]\n",
    "        rp_fp.ApplicationSetupSequence[0].ChannelSequence[idx].NumberOfControlPoints = len(rp_line)\n",
    "        rp_fp.ApplicationSetupSequence[0].ChannelSequence[idx].BrachyControlPointSequence.clear()\n",
    "        for pt_idx, pt in enumerate( rp_line ):\n",
    "            BCPPt = copy.deepcopy(BCPItemTemplate)\n",
    "            BCPPt.ControlPointRelativePosition = rp_ControlPointRelativePositions[idx] + pt_idx * 5\n",
    "            BCPPt.ControlPoint3DPosition[0] = pt[0]\n",
    "            BCPPt.ControlPoint3DPosition[1] = pt[1]\n",
    "            BCPPt.ControlPoint3DPosition[2] = pt[2]\n",
    "            BCPStartPt = copy.deepcopy(BCPPt)\n",
    "            BCPEndPt = copy.deepcopy(BCPPt)\n",
    "            BCPStartPt.ControlPointIndex = 2 * pt_idx\n",
    "            BCPEndPt.ControlPointIndex = 2 * pt_idx + 1\n",
    "            rp_fp.ApplicationSetupSequence[0].ChannelSequence[idx].BrachyControlPointSequence.append(BCPStartPt)\n",
    "            rp_fp.ApplicationSetupSequence[0].ChannelSequence[idx].BrachyControlPointSequence.append(BCPEndPt)\n",
    "\n",
    "    pydicom.write_file(out_rp_filepath, rp_fp)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def generate_brachy_rp_file(RP_OperatorsName, folder, out_rp_filepath):\n",
    "    print('folder = ', folder )\n",
    "    rs_filepath = ''\n",
    "    ct_filelist = []\n",
    "    for file in os.listdir(folder):\n",
    "        filepath = os.path.join(folder, file)\n",
    "        fp = pydicom.read_file(filepath)\n",
    "        if (fp.Modality == 'CT'):\n",
    "            ct_filelist.append(filepath)\n",
    "        elif (fp.Modality == 'RTSTRUCT'):\n",
    "            rs_filepath = filepath\n",
    "\n",
    "    # the function will get all 3D pt of applicator\n",
    "    app_pts = algo_run_by_folder(folder)\n",
    "    # transform all 3D pt of applicator into each line for each applicator and the line have been sorted by z\n",
    "    lines = make_lines_process(app_pts)\n",
    "    # The CT data is the format with 512 x 512, but we want to tranfer it into real metric space\n",
    "    metric_lines = convert_lines_in_metrics(lines, folder)\n",
    "    # Show the lines information in metrics\n",
    "    metric_tandem_line = metric_lines[1].copy()\n",
    "    metric_lt_ovoid_line = metric_lines[0].copy()\n",
    "    metric_rt_ovoid_line = metric_lines[2].copy()\n",
    "\n",
    "    print('metric_tandem_line = ', metric_tandem_line)\n",
    "    print('metric_lt_ovoid_line = ', metric_lt_ovoid_line)\n",
    "    print('metric_rt_ovoid_line = ', metric_rt_ovoid_line)\n",
    "\n",
    "    metric_tandem_line.reverse()\n",
    "    metric_lt_ovoid_line.reverse()\n",
    "    metric_rt_ovoid_line.reverse()\n",
    "\n",
    "    tandem_rp_line = get_applicator_rp_line(metric_tandem_line, 4, 5)\n",
    "    lt_ovoid_rp_line = get_applicator_rp_line(metric_lt_ovoid_line, 0, 5)\n",
    "    rt_ovoid_rp_line = get_applicator_rp_line(metric_rt_ovoid_line, 0 ,5)\n",
    "\n",
    "    print('tandem_rp_line = {}'.format(tandem_rp_line) )\n",
    "    print('lt_ovoid_rp_line = {}'.format(lt_ovoid_rp_line) )\n",
    "    print('rt_ovoid_rp_line = {}'.format(rt_ovoid_rp_line) )\n",
    "    wrap_to_rp_file(RP_OperatorsName, rs_filepath, tandem_rp_line, out_rp_filepath=out_rp_filepath, lt_ovoid_rp_line=lt_ovoid_rp_line, rt_ovoid_rp_line=rt_ovoid_rp_line)\n",
    "    print('out_rp_filepath = {}'.format(out_rp_filepath))\n",
    "\n",
    "#generate_brachy_rp_file(RP_OperatorsName='thoth', folder='RALmilo', out_rp_filepath=r'brachy.rp.dcm')\n",
    "#generate_brachy_rp_file(RP_OperatorsName='thoth', folder='16568131', out_rp_filepath=r'brachy.rp.dcm')\n",
    "#generate_brachy_rp_file(RP_OperatorsName='thoth', folder='24460566', out_rp_filepath=r'brachy.rp.dcm')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
